@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher M.},
  year={2006},
  publisher={Springer},
  address={New York}
}
@article{Schubert2023,
author = {Schubert, Erich},
title = {Stop using the elbow criterion for k-means and how to choose the number of clusters instead},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/3606274.3606278},
doi = {10.1145/3606274.3606278},
abstract = {A major challenge when using k-means clustering often is how to choose the parameter k, the number of clusters. In this letter, we want to point out that it is very easy to draw poor conclusions from a common heuristic, the "elbow method". Better alternatives have been known in literature for a long time, and we want to draw attention to some of these easy to use options, that often perform better. This letter is a call to stop using the elbow method altogether, because it severely lacks theoretic support, and we want to encourage educators to discuss the problems of the method - if introducing it in class at all - and teach alternatives instead, while researchers and reviewers should reject conclusions drawn from the elbow method.},
journal = {SIGKDD Explor. Newsl.},
month = jul,
pages = {36â€“42},
numpages = {7}
}
@misc{herdiana-2025,
	author = {Herdiana, Indra and Kamal, M Alfin and Triyani and Estri, Mutia Nur and Renny},
	month = {2},
	title = {{A more precise elbow method for optimum K-means clustering}},
	year = {2025},
	url = {https://arxiv.org/abs/2502.00851},
}
@article{dudoit-2002,
	author = {Dudoit, Sandrine and Fridlyand, Jane},
	journal = {Genome biology},
	month = {6},
	number = {7},
	title = {{A prediction-based resampling method for estimating the number of clusters in a dataset}},
	volume = {3},
	year = {2002},
	doi = {10.1186/gb-2002-3-7-research0036},
	url = {https://doi.org/10.1186/gb-2002-3-7-research0036},
}
@book{hastie2009elements,
  title={The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  edition={2nd},
  year={2009},
  publisher={Springer},
  address={New York}
}

@article{dempster1977maximum,
  title={Maximum likelihood from incomplete data via the EM algorithm},
  author={Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={39},
  number={1},
  pages={1--38},
  year={1977},
  publisher={Wiley}
}

@article{schwarz1978estimating,
  title={Estimating the dimension of a model},
  author={Schwarz, Gideon E.},
  journal={The Annals of Statistics},
  volume={6},
  number={2},
  pages={461--464},
  year={1978}
}

@article{fraley2002model,
  title={Model-based clustering, discriminant analysis, and density estimation},
  author={Fraley, Chris and Raftery, Adrian E.},
  journal={Journal of the American Statistical Association},
  volume={97},
  number={458},
  pages={611--631},
  year={2002},
  publisher={Taylor \& Francis}
}

@article{tibshirani2001estimating,
  title={Estimating the number of clusters in a data set via the Gap statistic},
  author={Tibshirani, R. and Walther, G. and Hastie, T.},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={63},
  number={2},
  pages={411--423},
  year={2001}
}

@article{calinski1974dendrite,
  title={A dendrite method for cluster analysis},
  author={Calinski, T. and Harabasz, J.},
  journal={Communications in Statistics},
  volume={3},
  number={1},
  pages={1--27},
  year={1974}
}

@article{man2021,
author = {Tudor Manole and Abbas Khalili},
title = {{Estimating the number of components in finite mixture models via the Group-Sort-Fuse procedure}},
volume = {49},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {3043 -- 3069},
keywords = {finite mixture models, maximum penalized likelihood estimation, strong identifiability, Wasserstein distance},
year = {2021},
doi = {10.1214/21-AOS2072},
URL = {https://doi.org/10.1214/21-AOS2072}
}
